{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Никита\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score,recall_score,precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./ml/labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                              Собаке - собачья смерть\\n    1.0\n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
       "...                                                  ...    ...\n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0\n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0\n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0\n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0\n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0\n",
       "\n",
       "[14412 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n      1\n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...      1\n",
       "2                              Собаке - собачья смерть\\n      1\n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...      1\n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...      1\n",
       "...                                                  ...    ...\n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...      1\n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...      1\n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...      0\n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...      1\n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...      0\n",
       "\n",
       "[14412 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"]=df[\"toxic\"].apply(int)\n",
    "#apply приводит к инту каждую строку (тк лучше их переводить в инт а не во флоат)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9586\n",
       "1    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].value_counts()\n",
    "#примерно 1 к 2 (те примерно данные сбалансированы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посмотрим на качество разметки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верблюдов-то за что? Дебилы, бл...\n",
      "\n",
      "Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
      "\n",
      "Собаке - собачья смерть\n",
      "\n",
      "Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
      "\n",
      "тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in df[df[\"toxic\"]==1][\"comment\"].head(5):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности.\n",
      "\n",
      "Почитайте посты у этого автора,может найдете что нибудь полезное. Надеюсь помог) https: pikabu.ru story obyichnyie budni dezsluzhbyi 4932098\n",
      "\n",
      "Про графику было обидно) я так то проходил все серии гта со второй части по пятую, кроме гта 4. И мне не мешала графика ни в одной из частей. На компе у меня было куча видеокарт. Начиная с 32мб RIVA TNT и заканчивая 2Гб 560Ti на которой я спокойно играю который год в танки, гта5, ведьмака3 купил на распродаже и начал проходить. Да, не на ультрах. С пониженными текстурами. И не мешает. Я не понимаю дрочева на графике, требовать графику уровня плойки 4 минимум. Мне надо чтобы глаза не резало, только и всего. По поводу управления, мне не хватает переходника на type c. У меня джойстик есть от иксбокса360. Потенциала в мобильных играх достаточно чтобы забить кнопки как забивались в той же NFS MW в 2005. Не самая плохая игра была.\n",
      "\n",
      "https: pp.userapi.com c848520 v848520411 11627b cOhWqFbGjWE.jpg\n",
      "\n",
      "Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in df[df[\"toxic\"]==0][\"comment\"].head(5):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#качество разметки неидеальное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df,test_size=500)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9258\n",
       "1    4654\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Будем использовать элементарную модель - логистическую регрессию,\n",
    "#но перед этим обработаем данные и сделаем из них вещественные векторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиваем сначала текст на токены\n",
    "# Удалить те токены, которые не несут смысла (междометия,знаки препинания)\n",
    "# к каждому слову применяем стеминг (удаляем окончание и приводим к нижнему регистру)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Никита\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') #загрузили стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_example =df.iloc[1][\"comment\"] #берем 1 комментарий\n",
    "tokens = word_tokenize(sentence_example, language=\"russian\") #функция из nltk(библ для анализа текста)\n",
    "#она разбивает по пробелам и по знакам пунктуации\n",
    "tokens_without_punctuation = [i for i in tokens if i not in string.punctuation] #этот массив содержит все знаки пунктуации (нашли их через string)\n",
    "russian_stop_words=stopwords.words(\"russian\") # из nltk получаем стоп слова русские\n",
    "tokens_without_stop_words_and_punctuation = [i for i in tokens_without_punctuation if i not in russian_stop_words] #и также удаляем стоп слова\n",
    "snowball = SnowballStemmer(language=\"russian\") \n",
    "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stop_words_and_punctuation] #приводим к нижеему регистру и удаляем окончания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
      "\n",
      "-----------------------------------\n",
      "Токены: ['Хохлы', ',', 'это', 'отдушина', 'затюканого', 'россиянина', ',', 'мол', ',', 'вон', ',', 'а', 'у', 'хохлов', 'еще', 'хуже', '.', 'Если', 'бы', 'хохлов', 'не', 'было', ',', 'кисель', 'их', 'бы', 'придумал', '.']\n",
      "-----------------------------------\n",
      "Токены без пунктуации: ['Хохлы', 'это', 'отдушина', 'затюканого', 'россиянина', 'мол', 'вон', 'а', 'у', 'хохлов', 'еще', 'хуже', 'Если', 'бы', 'хохлов', 'не', 'было', 'кисель', 'их', 'бы', 'придумал']\n",
      "-----------------------------------\n",
      "Токены без пунктуации и стоп слов: ['Хохлы', 'это', 'отдушина', 'затюканого', 'россиянина', 'мол', 'вон', 'хохлов', 'хуже', 'Если', 'хохлов', 'кисель', 'придумал']\n",
      "-----------------------------------\n",
      "Токены после стемминга: ['хохл', 'эт', 'отдушин', 'затюкан', 'россиянин', 'мол', 'вон', 'хохл', 'хуж', 'есл', 'хохл', 'кисел', 'придума']\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Исходный текст: {sentence_example}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Токены: {tokens}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Токены без пунктуации: {tokens_without_punctuation}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Токены без пунктуации и стоп слов: {tokens_without_stop_words_and_punctuation}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Токены после стемминга: {stemmed_tokens}\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализуем то же самое для всех предложений:\n",
    "snowball= SnowballStemmer(language=\"russian\") #загружаем алгоритм стемминга\n",
    "russian_stop_words = stopwords.words(\"russian\")\n",
    "\n",
    "def tokenize_sentence(sentence: str, remove_stop_words: bool=True):\n",
    "    tokens = word_tokenize(sentence,language=\"russian\") #токенизируем\n",
    "    tokens = [i for i in tokens if i not in string.punctuation] #удаляем пунтуацию\n",
    "    if remove_stop_words: #если нужно удаляем стоп слова\n",
    "        tokens = [i for i in tokens if i not in russian_stop_words]\n",
    "    tokens = [snowball.stem(i) for i in tokens] #делаем стемминг\n",
    "    return tokens\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хохл',\n",
       " 'эт',\n",
       " 'отдушин',\n",
       " 'затюкан',\n",
       " 'россиянин',\n",
       " 'мол',\n",
       " 'вон',\n",
       " 'хохл',\n",
       " 'хуж',\n",
       " 'есл',\n",
       " 'хохл',\n",
       " 'кисел',\n",
       " 'придума']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверим рабооту функции \n",
    "tokenize_sentence(sentence_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#закодируем последовательность токенов с TFIDF (без эмбеддингов) \n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True)) #переопределили токенайзер на наш\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13912x35426 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 218982 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим его и получим фичи которые уже можно передавать в модель мл\n",
    "features = vectorizer.fit_transform(train_df[\"comment\"])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0) #обеспечиваем воспроизводимость результатов\n",
    "model.fit(features, train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Зажигалкой коптиш ложку и собираеш\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"comment\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим конвейер \n",
    "model_pipeline =Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer(tokenizer=lambda x:tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x0000010D8B027AF0>)),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.fit(train_df[\"comment\"], train_df[\"toxic\"]) #обучаем пайплайн (мы передаем список предложений и их лейблы)\n",
    "#после этого для предикта сможем передавать уже просто текст "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"как дела как дела это новый кадиллак\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"ну-ка иди отсюда в ...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#метрики будут precision recall\n",
    "precision_score(y_true = test_df[\"toxic\"], y_pred = model_pipeline.predict(test_df[\"comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209302325581395"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true = test_df[\"toxic\"], y_pred= model_pipeline.predict(test_df[\"comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель логистическиой регрессии (предикт) возвращает вероятности и спранивает значение с порогом и потом делаем вывод\n",
    "#будем двигать threshold\n",
    "prec, rec, threshold = precision_recall_curve(y_true=test_df[\"toxic\"], probas_pred = model_pipeline.predict_proba(test_df[\"comment\"])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x10d8e13cb50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve(estimator=model_pipeline, X=test_df[\"comment\"],y=test_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "        356, 357, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372,\n",
       "        373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
       "        386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 401,\n",
       "        402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
       "        415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427,\n",
       "        428, 429, 430, 431, 432, 433, 434, 435, 436, 437], dtype=int64),)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#найдем индексы когда пресижн больше 0.95\n",
    "np.where(prec>0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6555944194634834"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold[364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958904109589041"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#вызовем предсказание с этим порогом \n",
    "precision_score(y_true=test_df[\"toxic\"],y_pred=model_pipeline.predict_proba(test_df[\"comment\"])[:,1]>threshold[364])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4069767441860465"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посчитаем рекол при этом пороге\n",
    "recall_score(y_true=test_df[\"toxic\"],y_pred=model_pipeline.predict_proba(test_df[\"comment\"])[:,1]>threshold[364])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#он вышел достаточно низкий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подберем гиперпараметры чтобы улучшить модель\n",
    "#будем менять коэф регуляризации C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим новый конвейер \n",
    "grid_pipeline =Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer(tokenizer=lambda x:tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\",GridSearchCV(LogisticRegression(random_state=0),\n",
    "                         param_grid={'C':[0.1,1,10.]}, #стандартный это 1\n",
    "                         cv=3, # три фолда во время кроссвалидации\n",
    "                         verbose=4)) #значит выводим максимум информации\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.688, total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.1, score=0.686, total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.688, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.834, total=   0.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.840, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.832, total=   0.3s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "C:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.859, total=   0.5s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.869, total=   0.4s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.866, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x0000010D8CD89820>)),\n",
       "                ('model',\n",
       "                 GridSearchCV(cv=3,\n",
       "                              estimator=LogisticRegression(random_state=0),\n",
       "                              param_grid={'C': [0.1, 1, 10.0]}, verbose=4))])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.fit(train_df[\"comment\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лучший скор получилось при c=10 но она не сошлась (попробуем обучить отдельно)\n",
    "#создадим конвейер \n",
    "model_pipeline_c_10 =Pipeline([\n",
    "    (\"vectorizer\",TfidfVectorizer(tokenizer=lambda x:tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0, C=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x0000010D8FDF5AF0>)),\n",
       "                ('model', LogisticRegression(C=10, random_state=0))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_c_10.fit(train_df[\"comment\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_c_10, rec_c_10, threshold_c_10 = precision_recall_curve(y_true=test_df[\"toxic\"], probas_pred = model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348,\n",
       "        349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
       "        362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
       "        375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "        388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400,\n",
       "        401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413,\n",
       "        414, 415, 416], dtype=int64),)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(prec_c_10>0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true=test_df[\"toxic\"],y_pred=model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:,1]>threshold_c_10[362])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3023255813953488"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true=test_df[\"toxic\"],y_pred=model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:,1]>threshold_c_10[362])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
